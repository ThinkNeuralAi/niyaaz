"""
Enhanced Multi-Module Video Processor with RTSP Connection Pooling
Handles multiple analysis modules on the same video feed with shared RTSP connections
"""
import cv2
import threading
import time
import logging
from queue import Queue
import numpy as np
from typing import List, Dict, Any, Optional


from .rtsp_connection_pool import rtsp_pool

logger = logging.getLogger(__name__)
def safe_array_check(obj, check_type="non_empty"):
    """
    Safe array validation that avoids ambiguous truth values
    
    Args:
        obj: Object to check (could be array, None, etc.)
        check_type: Type of check ('non_empty', 'valid', 'not_none')
    
    Returns:
        bool: True if object passes check, False otherwise
    """
    try:
        if obj is None:
            return False
        
        if not hasattr(obj, 'size'):
            return obj is not None  # For non-array objects
        
        if check_type == "non_empty":
            return obj.size > 0
        elif check_type == "valid":
            return hasattr(obj, 'shape') and obj.size > 0
        elif check_type == "not_none":
            return obj is not None
        else:
            return obj.size > 0
            
    except Exception as e:
        logger.error(f"Error in safe_array_check: {e}")
        return False

class SharedMultiModuleVideoProcessor:
    """
    Enhanced multi-module processor that uses shared RTSP connections
    """
    
        """
        Initialize Shared Multi-Module Video Processor
        
        Args:
            video_source: Path to video file, camera index, or RTSP URL
            channel_id: Unique identifier for the video channel
            fps_limit: Maximum FPS for processing
        """
        self.video_source = video_source
        self.channel_id = channel_id
        self.fps_limit = fps_limit
        self.frame_interval = 1.0 / fps_limit
        
        # Processing modules
        self.modules = {}  # {module_name: module_instance}
        self.module_results = {}  # {module_name: latest_result}
        
        # Threading and control
        self.is_running = False
        self.processing_thread = None
        
        # Frame management
        self.frame_queue = Queue(maxsize=5)
        self.latest_raw_frame = None
        self.latest_annotated_frame = None
        self.frame_lock = threading.Lock()
        
        # RTSP connection management
        self.rtsp_connection = None
        self.is_rtsp_stream = self._is_rtsp_url(video_source)
        
        # DeepStream processor (if enabled and available)
        self.processing_mode = None  # Will be set during initialization
        
        # Local video capture (for non-RTSP sources or fallback)
        self.cap = None
        
        # Shared YOLO detections cache
        self.shared_detections = None
        self.detections_lock = threading.Lock()
        self.detections_frame_id = 0
        
        # Performance tracking
        self.frames_processed = 0
        self.start_time = None
        self.actual_fps = 0
        
        logger.info(f"Shared multi-module processor initialized for channel {channel_id}")
        logger.info(f"Source type: {'RTSP' if self.is_rtsp_stream else 'Local'}")
    
    def _is_rtsp_url(self, source: str) -> bool:
        """Check if source is an RTSP URL"""
        if isinstance(source, str):
            return source.startswith(('rtsp://', 'rtmp://', 'http://', 'https://'))
        return False
    
    def _on_rtsp_frame(self, frame: np.ndarray):
        """
        Callback function for receiving frames from RTSP pool
        
        Args:
            frame: New frame from RTSP stream
        """
        try:
            # Validate frame using safe check
            if not safe_array_check(frame, "valid"):
                return
            
            # Add frame to processing queue
            if not self.frame_queue.full():
                self.frame_queue.put(frame, block=False)
            
            # Update latest raw frame
            with self.frame_lock:
                self.latest_raw_frame = frame
                
        except Exception as e:
            logger.error(f"Error handling RTSP frame for channel {self.channel_id}: {e}")
    
    def add_module(self, module_name: str, module_instance):
        """
        Add an analysis module to this video processor
        
        Args:
            module_name: Name of the module
            module_instance: Instance of the analysis module
        """
        self.modules[module_name] = module_instance
        self.module_results[module_name] = None
        logger.info(f"Added module '{module_name}' to channel {self.channel_id}")
    
    def remove_module(self, module_name: str):
        """Remove an analysis module"""
        if module_name in self.modules:
            del self.modules[module_name]
            del self.module_results[module_name]
            logger.info(f"Removed module '{module_name}' from channel {self.channel_id}")
    
    def get_active_modules(self) -> List[str]:
        """Get list of active module names"""
        return list(self.modules.keys())
    
    def initialize_capture(self):
        """
        Initialize video capture with DeepStream or fallback methods
        Priority: DeepStream (RTSP only) -> RTSP Pool -> Local OpenCV
        """
        try:
            # Attempt DeepStream for RTSP streams
                try:
                    logger.info(f"ðŸš€ Initializing DeepStream pipeline for: {self.video_source}")
                    
                except Exception as e:
                    logger.warning(f"DeepStream initialization failed: {e}")
                    logger.info("Falling back to RTSP connection pool")
            
            # Fallback to RTSP connection pool for RTSP streams
            if self.is_rtsp_stream and self.deepstream_processor is None:
                logger.info(f"Connecting to shared RTSP stream: {self.video_source}")
                self.rtsp_connection = rtsp_pool.get_connection(
                    rtsp_url=self.video_source,
                    channel_id=self.channel_id,
                    frame_callback=self._on_rtsp_frame
                )
                # Set pool reference for broadcasting
                self.rtsp_connection.set_pool(rtsp_pool)
                self.processing_mode = "RTSP Pool (GPU-accelerated)"
                
                # Wait a moment for first frame
                timeout = 5
                start_wait = time.time()
                while self.latest_raw_frame is None and (time.time() - start_wait) < timeout:
                    time.sleep(0.1)
                
                if self.latest_raw_frame is None:
                    raise ValueError(f"No frames received from RTSP stream: {self.video_source}")
                
                logger.info(f"Successfully connected to shared RTSP: {self.video_source}")
                return True
            
            # Local video capture for non-RTSP sources
            elif not self.is_rtsp_stream:
                if isinstance(self.video_source, str) and self.video_source.isdigit():
                    self.cap = cv2.VideoCapture(int(self.video_source))
                else:
                    self.cap = cv2.VideoCapture(self.video_source)
                
                if not self.cap.isOpened():
                    raise ValueError(f"Cannot open video source: {self.video_source}")
                
                # Optimize local capture settings
                self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 3)
                self.cap.set(cv2.CAP_PROP_FPS, self.fps_limit)
                self.processing_mode = "Local OpenCV"
                
                logger.info(f"Local video capture initialized: {self.video_source}")
                return True
            
            return True
            
        except Exception as e:
            logger.error(f"Failed to initialize capture for channel {self.channel_id}: {e}")
            return False
    
    def start(self):
        """Start video processing"""
        if self.is_running:
            logger.warning(f"Channel {self.channel_id} is already running")
            return False
        
        if not self.initialize_capture():
            return False
        
        self.is_running = True
        self.start_time = time.time()
        
        # Load configuration for all modules
        for module in self.modules.values():
            if hasattr(module, 'load_configuration'):
                module.load_configuration()
        
        # Start processing thread
        self.processing_thread = threading.Thread(target=self._processing_loop)
        self.processing_thread.daemon = True
        self.processing_thread.start()
        
        logger.info(f"Shared multi-module processing started for channel {self.channel_id}")
        return True
    
    def stop(self):
        """Stop video processing and cleanup resources"""
        self.is_running = False
        
        if self.processing_thread:
            self.processing_thread.join(timeout=5)
        
        # Cleanup DeepStream pipeline if active
        
        # Cleanup RTSP connection
        if self.is_rtsp_stream and self.rtsp_connection:
            rtsp_pool.unsubscribe(self.video_source, self.channel_id)
            self.rtsp_connection = None
        
        # Cleanup local capture
        if self.cap:
            self.cap.release()
        
        logger.info(f"Shared multi-module processing stopped for channel {self.channel_id}")
        logger.info(f"Processing mode was: {self.processing_mode}")
    
    def _processing_loop(self):
        """Main processing loop"""
        last_frame_time = 0
        consecutive_failures = 0
        max_failures = 30
        
        while self.is_running:
            try:
                current_time = time.time()
                
                # Respect FPS limit
                if current_time - last_frame_time < self.frame_interval:
                    time.sleep(0.001)
                    continue
                
                frame = None
                
                # Get frame based on processing mode
        logger.info(f"Processing loop ended for channel {self.channel_id}")
    
    def _create_combined_frame(self, original_frame: np.ndarray, 
                             module_results: Dict[str, Any]) -> np.ndarray:
        """
        Create combined frame with annotations from all modules
        
        Args:
            original_frame: Original video frame
            module_results: Dictionary of module processing results
            
        Returns:
            Frame with combined annotations from all modules
        """
        # Start with the original frame
        combined_frame = original_frame.copy()
        frame_height, frame_width = combined_frame.shape[:2]
        
        # Use the annotated frame from the first module that has one
        # Priority: PeopleCounter, QueueMonitor, others
        module_priority = ['PeopleCounter', 'QueueMonitor']
        
        for module_name in module_priority:
            if module_name in module_results:
                result = module_results[module_name]
                if result is not None and isinstance(result, dict) and 'frame' in result:
                    module_frame = result['frame']
                    if safe_array_check(module_frame, "valid"):
                        combined_frame = module_frame.copy()
                        logger.debug(f"Using annotated frame from {module_name}")
                        break
        
        # If no priority module found, use any available annotated frame
        if np.array_equal(combined_frame, original_frame):
            for module_name, result in module_results.items():
                if result is not None and isinstance(result, dict) and 'frame' in result:
                    module_frame = result['frame']
                    if safe_array_check(module_frame, "valid"):
                        combined_frame = module_frame.copy()
                        logger.debug(f"Using annotated frame from {module_name}")
                        break
        
        # Draw header showing active modules
        header_height = 40
        header_frame = np.zeros((header_height, frame_width, 3), dtype=np.uint8)
        
        # List active modules
        module_names = list(module_results.keys())
        if module_names:
            header_text = f"Shared RTSP - Active: {', '.join(module_names)}"
            cv2.putText(header_frame, header_text, (10, 25), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 1)
        
        # Add RTSP sharing indicator
        if self.is_rtsp_stream:
            pool_stats = rtsp_pool.get_connection_stats()
            if self.video_source in pool_stats:
                subscriber_count = pool_stats[self.video_source]['subscribers']
                sharing_text = f"Shared with {subscriber_count} channel(s)"
                cv2.putText(header_frame, sharing_text, (frame_width - 300, 25),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
        
        # Add additional module status overlays (without duplicating the main annotations)
        y_offset = 60
        for i, (module_name, result) in enumerate(module_results.items()):
            if result is not None and isinstance(result, dict) and 'status' in result:
                if module_name == 'PeopleCounter':
                    self._overlay_people_counter_status(combined_frame, result, y_offset + i * 25)
                elif module_name == 'QueueMonitor':
                    self._overlay_queue_monitor_status(combined_frame, result, y_offset + i * 25)
        
        # Combine header with main frame
        final_frame = np.vstack([header_frame, combined_frame])
        return final_frame
    
    def _overlay_people_counter_status(self, frame, result, y_pos):
        """Overlay people counter status information (small overlay)"""
        if result is not None and isinstance(result, dict) and 'status' in result:
            status = result['status']
            if status is not None and isinstance(status, dict):
                in_count = status.get('in_count', 0)
                out_count = status.get('out_count', 0)
                detections = status.get('detections', 0)
                
                # Small status overlay in top-right corner
                status_text = f"PC: IN:{in_count} OUT:{out_count} DET:{detections}"
                cv2.putText(frame, status_text, (frame.shape[1] - 300, y_pos), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
    
    def _overlay_queue_monitor_status(self, frame, result, y_pos):
        """Overlay queue monitor status information (small overlay)"""
        if result is not None and isinstance(result, dict) and 'status' in result:
            status = result['status']
            if status is not None and isinstance(status, dict):
                queue_count = status.get('queue_count', 0)
                counter_count = status.get('counter_count', 0)
                
                # Small status overlay in top-right corner
                status_text = f"QM: Q:{queue_count} C:{counter_count}"
                color = (0, 255, 255) if queue_count <= 2 else (0, 0, 255)
                cv2.putText(frame, status_text, (frame.shape[1] - 200, y_pos), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
    
    def get_latest_frame(self, module_name: Optional[str] = None) -> np.ndarray:
        """
        Get the latest processed frame
        
        Args:
            module_name: If specified, get frame from specific module
            
        Returns:
            Latest frame (combined or module-specific)
        """
        with self.frame_lock:
            if module_name and module_name in self.module_results:
                result = self.module_results[module_name]
                if result is not None and isinstance(result, dict) and 'frame' in result:
                    frame = result['frame']
                    if safe_array_check(frame, "valid"):
                        return frame
            
            # Return combined frame if available
            if safe_array_check(self.latest_annotated_frame, "valid"):
                return self.latest_annotated_frame
            elif safe_array_check(self.latest_raw_frame, "valid"):
                return self.latest_raw_frame
            else:
                return np.zeros((480, 640, 3), dtype=np.uint8)
    
    def get_module_result(self, module_name: str):
        """Get the latest result from a specific module"""
        return self.module_results.get(module_name)
    
    def get_all_module_results(self):
        """Get results from all modules"""
        return self.module_results.copy()
    
    def get_status(self):
        """Get processor status including DeepStream and RTSP sharing info"""
        elapsed_time = time.time() - self.start_time if self.start_time else 0
        avg_fps = self.frames_processed / elapsed_time if elapsed_time > 0 else 0
        
        module_statuses = {}
        for module_name, module in self.modules.items():
            if hasattr(module, 'get_status'):
                module_statuses[module_name] = module.get_status()
        
        # Get RTSP sharing information
        rtsp_info = {}
        if self.is_rtsp_stream and self.rtsp_connection:
            pool_stats = rtsp_pool.get_connection_stats()
            if self.video_source in pool_stats:
                rtsp_info = pool_stats[self.video_source]
        
        # Get DeepStream statistics if active
        return {
            'channel_id': self.channel_id,
            'is_running': self.is_running,
            'video_source': self.video_source,
            'processing_mode': self.processing_mode or 'Unknown',
            'source_type': 'RTSP (Shared)' if self.is_rtsp_stream else 'Local',
            'hardware_accelerated': self.is_rtsp_stream and self.rtsp_connection is not None,
            'frames_processed': self.frames_processed,
            'elapsed_time': elapsed_time,
            'average_fps': avg_fps,
            'actual_fps': self.actual_fps,
            'target_fps': self.fps_limit,
            'active_modules': list(self.modules.keys()),
            'num_modules': len(self.modules),
            'module_statuses': module_statuses,
            'rtsp_sharing': rtsp_info,
            'performance_mode': self.processing_mode or 'Unknown'
        }